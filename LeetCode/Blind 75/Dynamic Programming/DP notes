Dynamic Programming

Dynamic programming is an algorithmic optimization technique that breaks down a complicated problem into smaller
overlapping sub-problems in a recursive manner and uses solutions to the sub-problems to construct a solution to the
original problem.

Characteristics of Dynamic Programming
A problem is a dynamic programming problem if it satisfies two conditions:
    1. The problem can be divided into sub-problems, and its optimal solution can be constructed from optimal solutions
       of the sub-problems. In academic terms, this is called optimal substructure.
    2. The sub-problems from 1) overlap.

DP == DFS + memoization + pruning

How to Solve Dynamic Programming Problems?
    -Top-down: this is basically DFS + memoization as we have seen memoization. We split large problems and recursively
               solve smaller sub-problems.
        1. Draw the tree: see the tree above
        2. Identify states
           -What state do we need to know if we have reached a solution? We need to know the value of n we are computing
           -What state do we need to decide which child nodes to visit next? No extra state is required. We always visit
            n-1 and n-2.
        3. DFS + pruning (if needed) + memoization

        def fib(n, memo):
            if n in memo: # check for the solution in the memo, if found, return it right away
                return memo[n]

            if n == 0 or n == 1:
                return n

            res = fib(n - 1, memo) + fib(n - 2, memo)

            memo[n] = res # save the solution in memo before returning
            return res

    -Bottom-up: we try to solve sub-problems and then use their solutions to find the solutions to bigger sub-problems.
                This is usually done in a tabular form.

         def fib(n):
            dp = [0, 1]
            for i in range(2, n + 1):
              dp.append(dp[i - 1] + dp[i - 2])

            return dp[-1]


Should I do top-down or bottom-up?
Top-down pros:
    -The order of computing sub-problems doesn't matter. For bottom-up, we have to fill the table in order to solve all
     the sub-problems first. For example, to fill dp[8], we have to have filled dp[6] and dp[7] first. For top-down, we
     can let recursion and memoization take care of the sub-problems and, therefore, not worry about the order.
    -Easier to the reason for partition type of problems (how many ways are there too.., splitting a string into...).
     Just do DFS and add memoization.

Bottom-up pros:
    -Easier to analyze the time complexity (since it's just the time to fill the table)
    -No recursion, and thus no system stack overflowâ€”although not a huge concern for normal coding interviews.


When to use dynamic programming
Mathematically, dynamic programming is an optimization method on one or more sequences (e.g., arrays, matrices). So
questions asking about the optimal way to do something on one or more sequences are often a good candidate for dynamic
programming. Signs of dynamic programming:
    -The problem asks for the maximum/longest, minimal/shortest value/cost/profit you can get from doing operations on a
     sequence.
    -You've tried greedy, but it sometimes gives the wrong solution. This often means you have to consider sub-problems
     for an optimal solution.
    -The problem asks how many ways there are to do something. This can often be solved by DFS + memoization,
     i.e., top-down dynamic programming.
    -Partition a string/array into sub-sequences so that a specific condition is met. This is often well-suited for
     top-down dynamic programming.
    -The problem is about the optimal way to play a game.
