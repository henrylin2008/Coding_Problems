Dynamic Programming

Dynamic programming is an algorithmic optimization technique that breaks down a complicated problem into smaller
overlapping sub-problems in a recursive manner and uses solutions to the sub-problems to construct a solution to the
original problem.

Characteristics of Dynamic Programming
A problem is a dynamic programming problem if it satisfies two conditions:
    1. The problem can be divided into sub-problems, and its optimal solution can be constructed from optimal solutions
       of the sub-problems. In academic terms, this is called optimal substructure.
    2. The sub-problems from 1) overlap.

DP == DFS + memoization + pruning

How to Solve Dynamic Programming Problems?
    -Top-down: this is basically DFS + memoization as we have seen memoization. We split large problems and recursively
               solve smaller sub-problems.
        1. Draw the tree: see the tree above
        2. Identify states
           -What state do we need to know if we have reached a solution? We need to know the value of n we are computing
           -What state do we need to decide which child nodes to visit next? No extra state is required. We always visit
            n-1 and n-2.
        3. DFS + pruning (if needed) + memoization

        def fib(n, memo):
            if n in memo: # check for the solution in the memo, if found, return it right away
                return memo[n]

            if n == 0 or n == 1:
                return n

            res = fib(n - 1, memo) + fib(n - 2, memo)

            memo[n] = res # save the solution in memo before returning
            return res

    -Bottom-up: we try to solve sub-problems and then use their solutions to find the solutions to bigger sub-problems.
                This is usually done in a tabular form.

         def fib(n):
            dp = [0, 1]
            for i in range(2, n + 1):
              dp.append(dp[i - 1] + dp[i - 2])

            return dp[-1]


Should I do top-down or bottom-up?
Top-down pros:
    -The order of computing sub-problems doesn't matter. For bottom-up, we have to fill the table in order to solve all
     the sub-problems first. For example, to fill dp[8], we have to have filled dp[6] and dp[7] first. For top-down, we
     can let recursion and memoization take care of the sub-problems and, therefore, not worry about the order.
    -Easier to the reason for partition type of problems (how many ways are there too.., splitting a string into...).
     Just do DFS and add memoization.

Bottom-up pros:
    -Easier to analyze the time complexity (since it's just the time to fill the table)
    -No recursion, and thus no system stack overflowâ€”although not a huge concern for normal coding interviews.


When to use dynamic programming
Mathematically, dynamic programming is an optimization method on one or more sequences (e.g., arrays, matrices). So
questions asking about the optimal way to do something on one or more sequences are often a good candidate for dynamic
programming. Signs of dynamic programming:
    -The problem asks for the maximum/longest, minimal/shortest value/cost/profit you can get from doing operations on a
     sequence.
    -You've tried greedy, but it sometimes gives the wrong solution. This often means you have to consider sub-problems
     for an optimal solution.
    -The problem asks how many ways there are to do something. This can often be solved by DFS + memoization,
     i.e., top-down dynamic programming.
    -Partition a string/array into sub-sequences so that a specific condition is met. This is often well-suited for
     top-down dynamic programming.
    -The problem is about the optimal way to play a game.


Dynamic Programming Patterns

Weight-only Knapsack
This is the most common type of DP problem and an excellent place to get a feel of dynamic programming and how it's
different from brute force backtracking. The state in these problems is a two-variable pair instead of the
single-variable state we have seen so far in backtracking.
    -Knapsack - given a number of items of different weights, is it possible to use the items to make up weight X?
    -Partition an array into two equal sum subsets - is it possible to divide an array into two subsets with equal sum?
    -0-1 Knapsack - same as weight-only knapsack except items have values, and the goal is to find the maximum object
     value we can put in our knapsack without exceeding the allowed weight.

Grid
The state in this type of DP is often the grid itself. dp[i][j] means max/min/best value for matrix cell ending at index
i, j.
    -Robot unique paths - number of ways for robot to move from top left to bottom right
    -Min path sum - find path in a grid with minimum cost
    -Maximal square - find maximal square of 1s in a grid of 0s and 1s

Game theory
This type of problem asks whether a player can win a decision game. The key to solving game theory problems is to
identify a winning state, and formulate a winning state as a state that returns a losing state to the opponent
    -Divisor game These problems are often closely related to the following Interval DP problems.

Interval
The key to solving this type of problem involves finding a sub-problem defined on an interval dp[i][j].
    -Coin game - two players play a game by removing coins from either end of a row of coins. Find the maximum store.
    -Festival game, bursting balloons - similar to the coin game problem but with a different way of evaluating scores.

Two Sequences
This type of problem has two sequences in its problem statement. dp[i][j] represents the max/min/best value for the first
 sequence ending in index i and the second sequence ending in index j.
    -Longest common subsequence - find the longest common subsequence that is common in two sequences
    -Edit distance - find the minimum distance to edit one string to another

Dynamic number of sub-problems, Longest Increasing Subsequence
This type of DP problem is unique in that the current state depends on a dynamic number of previous states,
e.g. dp[i] = max(d[j]..) for j from 0 to i.
    -Longest Increasing Subsequence - find the longest increasing subsequence of an array of numbers
    -Buy/sell the stock with at most K transactions - maximize profit by buying and selling stocks using at most K transaction

Bitmask
These DP problems use bitmasks to reduce factorial complexity (n!) to 2^n by encoding the dp state in bitmasks.
    -Longest Path in a DAG - find the longest path in a directed acyclic graph.
    -Minimum Cost to Visit Every Node in a Graph - find the minimum cost to traverse every node in a directed weighted graph